<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> publications | Hayoung Jung </title> <meta name="author" content="Hayoung Jung"> <meta name="description" content="M.S. student at UW CSE "> <meta name="keywords" content="NLP, AI Ethics, Computational Social Science, UW"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%A6%9B&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://hayoungjungg.github.io/publications/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Hayoung</span> Jung </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/publications/">publications <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/assets/pdf/cv.pdf">cv </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">publications</h1> <p class="post-description"></p> </header> <article> <p>For most up-to-date list of my publications, please visit my <a href="https://scholar.google.com/citations?user=5OJnFjkAAAAJ&amp;hl=en" rel="external nofollow noopener" target="_blank">Google Scholar profile.</a></p> <div class="publications"> <h2>preprint</h2> <h2 class="bibliography">2025</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="kaur" class="col-sm-8"> <div class="title">Who’s Asking? Simulating Role-Based Questions for Conversational AI Evaluation</div> <div class="author"> </div> <div class="periodical"> <em>In Will be uploaded soon!</em>, 2025 <span style="color: #DAA520"></span> </div> <div class="periodical"> </div> <div class="links"> <a href="" class="btn btn-sm z-depth-0" role="button">URL</a> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> </div> <div class="abstract hidden"> <p>Language model users often embed personal and social context in their questions. The asker’s role—implicit in how the question is framed—creates specific needs for an appropriate response. However, most evaluations, while capturing the model’s capability to respond, often ignore who is asking. This gap is especially critical in stigmatized domains such as opioid use disorder (OUD), where accounting for users’ contexts is essential to provide accessible, stigma-free responses. We propose CORUS (COmmunity-driven Roles for User-centric Question Simulation), a framework for simulating role-based questions. Drawing on role theory and posts from an online OUD recovery community (r/OpiatesRecovery), we first build a taxonomy of asker roles—patients, caregivers, practitioners. Next, we use it to simulate 15,321 questions that embed each role’s goals, behaviors, and experiences. Our evaluations show that these questions are both highly believable and comparable to real-world data. When used to evaluate five LLMs, for the same question but differing roles, we find systematic differences: vulnerable roles, such as patients and caregivers, elicit more supportive responses (+17%) and reduced knowledge content (-19%) in comparison to practitioners. Our work demonstrates how implicitly signaling a user’s role shapes model responses, and provides a methodology for role-informed evaluation of conversational AI.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="phutane2025ableistintersectionaldisabilitybias" class="col-sm-8"> <div class="title">ABLEIST: Intersectional Disability Bias in LLM-Generated Hiring Scenarios</div> <div class="author"> Mahika Phutane<sup>*</sup>, <em>Hayoung Jung<sup>*</sup></em>, Matthew Kim, Tanushree Mitra, and Aditya Vashistha </div> <div class="periodical"> <em>In </em>, 2025 <span style="color: #DAA520"></span> </div> <div class="periodical"> </div> <div class="links"> <a href="https://arxiv.org/abs/2510.10998" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">URL</a> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://github.com/hayoungjungg/ABLEIST" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="https://huggingface.co/hayoungjung/llama3.1-8b-adapter-ABLEist-detection" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Model</a> </div> <div class="abstract hidden"> <p>Large language models (LLMs) are increasingly under scrutiny for perpetuating identity-based discrimination in high-stakes domains such as hiring, particularly against people with disabilities (PwD). However, existing research remains largely Western-centric, overlooking how intersecting forms of marginalization–such as gender and caste–shape experiences of PwD in the Global South. We conduct a comprehensive audit of six LLMs across 2,820 hiring scenarios spanning diverse disability, gender, nationality, and caste profiles. To capture subtle intersectional harms and biases, we introduce ABLEIST (Ableism, Inspiration, Superhumanization, and Tokenism), a set of five ableism-specific and three intersectional harm metrics grounded in disability studies literature. Our results reveal significant increases in ABLEIST harms towards disabled candidates–harms that many state-of-the-art models failed to detect. These harms were further amplified by sharp increases in intersectional harms (e.g., Tokenism) for gender and caste-marginalized disabled candidates, highlighting critical blind spots in current safety tools and the need for intersectional safety evaluations of frontier models in high-stakes domains like hiring.</p> </div> </div> </div> </li> </ol> <h2>conference &amp; journal articles</h2> <h2 class="bibliography">2025</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">EMNLP</abbr> </div> <div id="jung2025mythtriagescalabledetectionopioid" class="col-sm-8"> <div class="title">MythTriage: Scalable Detection of Opioid Use Disorder Myths on a Video-Sharing Platform</div> <div class="author"> <em>Hayoung Jung</em>, Shravika Mittal, Ananya Aatreya, Navreet Kaur, Munmun De Choudhury, and Tanushree Mitra </div> <div class="periodical"> <em>In Proceedings of the 2025 Conference on Empirical Methods in Natural Language Processing</em>, 2025 <span style="color: #DAA520"></span> </div> <div class="periodical"> </div> <div class="links"> <a href="https://arxiv.org/abs/2506.00308" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">URL</a> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://github.com/hayoungjungg/MythTriage" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Data</a> <a href="https://github.com/hayoungjungg/MythTriage/tree/main/code" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="https://huggingface.co/SocialCompUW/youtube-opioid-myth-detect-M1" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Model</a> <a href="/assets/pdf/EMNLP_2025_main-349_slides.pdf" class="btn btn-sm z-depth-0" role="button">Slides</a> </div> <div class="abstract hidden"> <p>Understanding the prevalence of misinformation in health topics online can inform public health policies and interventions. However, measuring such misinformation at scale remains a challenge, particularly for high-stakes but understudied topics like opioid-use disorder (OUD)–a leading cause of death in the U.S. We present the first large-scale study of OUD-related myths on YouTube, a widely-used platform for health information. With clinical experts, we validate 8 pervasive myths and release an expert-labeled video dataset. To scale labeling, we introduce MythTriage, an efficient triage pipeline that uses a lightweight model for routine cases and defers harder ones to a high-performing, but costlier, large language model (LLM). MythTriage achieves up to 0.86 macro F1-score while estimated to reduce annotation time and financial cost by over 76% compared to experts and full LLM labeling. We analyze 2.9K search results and 343K recommendations, uncovering how myths persist on YouTube and offering actionable insights for public health and platform moderation.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">ICWSM</abbr> </div> <div id="Jung_Juneja_Mitra_2025" class="col-sm-8"> <div class="title">Algorithmic Behaviors Across Regions: A Geolocation Audit of YouTube Search for COVID-19 Misinformation Between the United States and South Africa</div> <div class="author"> <em>Hayoung Jung</em>, Prerna Juneja, and Tanushree Mitra </div> <div class="periodical"> <em>In Proceedings of the International AAAI Conference on Web and Social Media (ICWSM)</em>, 2025 <span style="color: #DAA520"></span> </div> <div class="periodical"> </div> <div class="links"> <a href="https://ojs.aaai.org/index.php/ICWSM/article/view/35854" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">URL</a> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://github.com/social-comp/YouTubeAuditGeolocation-data" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Data</a> <a href="https://huggingface.co/SocialCompUW/youtube-covid-misinfo-detect" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Model</a> <a href="/assets/pdf/youtube-geolocation-slides.pdf" class="btn btn-sm z-depth-0" role="button">Slides</a> </div> <div class="abstract hidden"> <p>Despite being an integral tool for finding health-related information online, YouTube has faced criticism for disseminating COVID-19 misinformation globally to its users. Yet, prior audit studies have predominantly investigated YouTube within the Global North contexts, often overlooking the Global South. To address this gap, we conducted a comprehensive 10-day geolocation-based audit on YouTube to compare the prevalence of COVID-19 misinformation in search results between the United States (US) and South Africa (SA), the countries heavily affected by the pandemic in the Global North and the Global South, respectively. For each country, we selected 3 geolocations and placed sock-puppets, or bots emulating "real" users, that collected search results for 48 search queries sorted by 4 search filters for 10 days, yielding a dataset of 915K results. We found that 31.55% of the top-10 search results contained COVID-19 misinformation. Among the top-10 search results, bots in SA faced significantly more misinformative search results than their US counterparts. Overall, our study highlights the contrasting algorithmic behaviors of YouTube search between two countries, underscoring the need for the platform to regulate algorithmic behavior consistently across different regions of the Globe.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">ICWSM</abbr> </div> <div id="mittal2025oudmythsredditllm" class="col-sm-8"> <div class="title">Online Myths on Opioid Use Disorder: A Comparison of Reddit and Large Language Model</div> <div class="author"> Shravika Mittal, <em>Hayoung Jung</em>, Mai ElSherief, Tanushree Mitra, and Munmun De Choudhury </div> <div class="periodical"> <em>In Proceedings of the International AAAI Conference on Web and Social Media (ICWSM)</em>, 2025 <span style="color: #DAA520"></span> </div> <div class="periodical"> </div> <div class="links"> <a href="https://ojs.aaai.org/index.php/ICWSM/article/view/35870" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">URL</a> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://github.com/anonymous-user-25/OUD-myths" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="/assets/pdf/reddit-llm-oud.pdf" class="btn btn-sm z-depth-0" role="button">Slides</a> </div> <div class="abstract hidden"> <p>Online communities on Reddit are a popular choice among people with opioid use disorder (OUD) to seek information on drug use, withdrawal symptoms, and recovery. LLMpowered chatbots (e.g., ChatGPT) are widely being adopted as question-answer systems for health-related queries. However, such online health information seeking could potentially be hindered by myths and misinformation on OUD, misleading or causing genuine harm to people with OUD. In this work, we examine the prevalence of 5 OUD-related myths, on treatment models and patient characteristics, within human-(taken from Reddit) and LLM-generated responses to queries on OUD. We further explore the framing strategies used within responses (both human- and LLM-generated) promoting and countering the myths. We found that all 5 myths were more widespread within human-generated responses. In addition, myth-promoting responses adopted trustworthy and authoritative framings, compared to knowledge-imparting linguistic cues within those countering the myths. Our work offers recommendations to reduce online OUD misinformation.</p> </div> </div> </div> </li> </ol> <h2 class="bibliography">2024</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">EMNLP</abbr> </div> <div id="park-etal-2024-valuescope" class="col-sm-8"> <div class="title">ValueScope: Unveiling Implicit Norms and Values via Return Potential Model of Social Interactions</div> <div class="author"> Chan Young Park<sup>*</sup>, Shuyue Stella Li<sup>*</sup>, <em>Hayoung Jung<sup>*</sup></em>, Svitlana Volkova, Tanu Mitra, David Jurgens, and Yulia Tsvetkov </div> <div class="periodical"> <em>In Findings of the Association for Computational Linguistics: EMNLP 2024</em>, Nov 2024 <span style="color: #DAA520"></span> </div> <div class="periodical"> </div> <div class="links"> <a href="https://aclanthology.org/2024.findings-emnlp.972" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">URL</a> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://github.com/stellalisy/valueScope" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="/assets/pdf/valuescope-poster.pdf" class="btn btn-sm z-depth-0" role="button">Poster</a> </div> <div class="abstract hidden"> <p>This study introduces ValueScope, a framework leveraging language models to quantify social norms and values within online communities, grounded in social science perspectives on normative structures. We employ ValueScope to dissect and analyze linguistic and stylistic expressions across 13 Reddit communities categorized under gender, politics, science, and finance. Our analysis provides a quantitative foundation confirming that even closely related communities exhibit remarkably diverse norms. This diversity supports existing theories and adds a new dimension to understanding community interactions. ValueScope not only delineates differences in social norms but also effectively tracks their evolution and the influence of significant external events like the U.S. presidential elections and the emergence of new sub-communities. The framework thus highlights the pivotal role of social norms in shaping online interactions, presenting a substantial advance in both the theory and application of social norm studies in digital spaces.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">EMNLP</abbr> </div> <div id="dammu-etal-2024-uncultured" class="col-sm-8"> <div class="title">“They are uncultured”: Unveiling Covert Harms and Social Threats in LLM Generated Conversations</div> <div class="author"> Preetam Prabhu Srikar Dammu<sup>*</sup>, <em>Hayoung Jung<sup>*</sup></em>, Anjali Singh, Monojit Choudhury, and Tanu Mitra </div> <div class="periodical"> <em>In Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing</em>, Nov 2024 <span style="color: #DAA520">– Nominated for the Best Paper Award</span> </div> <div class="periodical"> </div> <div class="links"> <a href="https://aclanthology.org/2024.emnlp-main.1134" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">URL</a> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://huggingface.co/SocialCompUW/CHAST" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Model</a> <a href="/assets/pdf/llm-culture-slides.pdf" class="btn btn-sm z-depth-0" role="button">Slides</a> <a href="https://www.washington.edu/news/2024/11/20/ai-chatbots-chatgpt-hiring-bias-caste-race/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">UW News</a> <a href="https://www.technologyreview.com/2025/10/01/1124621/openai-india-caste-bias/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">MIT Technology Review</a> </div> <div class="abstract hidden"> <p>Large language models (LLMs) have emerged as an integral part of modern societies, powering user-facing applications such as personal assistants and enterprise applications like recruitment tools. Despite their utility, research indicates that LLMs perpetuate systemic biases. Yet, prior works on LLM harms predominantly focus on Western concepts like race and gender, often overlooking cultural concepts from other parts of the world. Additionally, these studies typically investigate “harm” as a singular dimension, ignoring the various and subtle forms in which harms manifest. To address this gap, we introduce the Covert Harms and Social Threats (CHAST), a set of seven metrics grounded in social science literature. We utilize evaluation models aligned with human assessments to examine the presence of covert harms in LLM-generated conversations, particularly in the context of recruitment. Our experiments reveal that seven out of the eight LLMs included in this study generated conversations riddled with CHAST, characterized by malign views expressed in seemingly neutral language unlikely to be detected by existing methods. Notably, these LLMs manifested more extreme views and opinions when dealing with non-Western concepts like caste, compared to Western ones such as race.</p> </div> </div> </div> </li> </ol> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Hayoung Jung. Last updated: October 18, 2025. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>